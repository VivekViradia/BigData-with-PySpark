{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f8c738",
   "metadata": {},
   "source": [
    "# Pyspark Handling Missing Values\n",
    "Dropping Columns\n",
    "\n",
    "Dropping Rows\n",
    "\n",
    "Various Parameter In Dropping functionalities\n",
    "\n",
    "Handling Missing values by Mean, Median And Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa39a34",
   "metadata": {},
   "source": [
    "# Starting Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2d962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25920f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Handling Values').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1463bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-145GI0U:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Handling Values</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2a5d1628b50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3362488",
   "metadata": {},
   "source": [
    "# Loading DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c899e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+----+----------+----+\n",
      "|  0|First Name|Last Name|Gender|      Country| Age|      Date|  Id|\n",
      "+---+----------+---------+------+-------------+----+----------+----+\n",
      "|  1|     Dulce|    Abril|Female|United States|  32|15-10-2017|1562|\n",
      "|  2|      Mara|Hashimoto|Female|Great Britain|  25|16-08-2016|1582|\n",
      "|  3|    Philip|     Gent|  Male|       France|  36|21-05-2015|2587|\n",
      "|  4|  Kathleen|   Hanner|Female|United States|  25|15-10-2017|3549|\n",
      "|  5|   Nereida|  Magwood|Female|United States|  58|16-08-2016|2468|\n",
      "|  6|    Gaston|    Brumm|  Male|United States|  24|21-05-2015|2554|\n",
      "|  7|      Etta|     Hurn|Female|Great Britain|  56|15-10-2017|3598|\n",
      "|  8|   Earlean|   Melgar|Female|United States|  27|16-08-2016|2456|\n",
      "|  9|  Vincenza|  Weiland|Female|United States|  40|21-05-2015|6548|\n",
      "| 10|      null| Vachhani|  null|        India|  23|      null|5647|\n",
      "| 11|     Vivek|     null|  Male|        India|null|      null|6666|\n",
      "| 12|      null|    Patel|  null|         null|  26|      null|9999|\n",
      "+---+----------+---------+------+-------------+----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading dataset\n",
    "#spark.read.csv('file_example_1.csv',header=True,inferschema=True)\n",
    "df_spark = spark.read.option('header','true').csv('file_example_1.csv',inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ddad3",
   "metadata": {},
   "source": [
    "# Handling Data\n",
    "\n",
    "## Drop NULL Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72b12445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+----+\n",
      "|  0|First Name|Last Name|Gender|      Country| Age|\n",
      "+---+----------+---------+------+-------------+----+\n",
      "|  1|     Dulce|    Abril|Female|United States|  32|\n",
      "|  2|      Mara|Hashimoto|Female|Great Britain|  25|\n",
      "|  3|    Philip|     Gent|  Male|       France|  36|\n",
      "|  4|  Kathleen|   Hanner|Female|United States|  25|\n",
      "|  5|   Nereida|  Magwood|Female|United States|  58|\n",
      "|  6|    Gaston|    Brumm|  Male|United States|  24|\n",
      "|  7|      Etta|     Hurn|Female|Great Britain|  56|\n",
      "|  8|   Earlean|   Melgar|Female|United States|  27|\n",
      "|  9|  Vincenza|  Weiland|Female|United States|  40|\n",
      "| 10|      null| Vachhani|  null|        India|  23|\n",
      "| 11|     Vivek|     null|  Male|        India|null|\n",
      "| 12|      null|    Patel|  null|         null|  26|\n",
      "+---+----------+---------+------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## drop NUll columns\n",
    "df_spark = df_spark.drop('Date','Id')\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c40007d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+---+\n",
      "|  0|First Name|Last Name|Gender|      Country|Age|\n",
      "+---+----------+---------+------+-------------+---+\n",
      "|  1|     Dulce|    Abril|Female|United States| 32|\n",
      "|  2|      Mara|Hashimoto|Female|Great Britain| 25|\n",
      "|  3|    Philip|     Gent|  Male|       France| 36|\n",
      "|  4|  Kathleen|   Hanner|Female|United States| 25|\n",
      "|  5|   Nereida|  Magwood|Female|United States| 58|\n",
      "|  6|    Gaston|    Brumm|  Male|United States| 24|\n",
      "|  7|      Etta|     Hurn|Female|Great Britain| 56|\n",
      "|  8|   Earlean|   Melgar|Female|United States| 27|\n",
      "|  9|  Vincenza|  Weiland|Female|United States| 40|\n",
      "+---+----------+---------+------+-------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Will delete all the rows with NULL values\n",
    "df_spark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1a84362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+---+\n",
      "|  0|First Name|Last Name|Gender|      Country|Age|\n",
      "+---+----------+---------+------+-------------+---+\n",
      "|  1|     Dulce|    Abril|Female|United States| 32|\n",
      "|  2|      Mara|Hashimoto|Female|Great Britain| 25|\n",
      "|  3|    Philip|     Gent|  Male|       France| 36|\n",
      "|  4|  Kathleen|   Hanner|Female|United States| 25|\n",
      "|  5|   Nereida|  Magwood|Female|United States| 58|\n",
      "|  6|    Gaston|    Brumm|  Male|United States| 24|\n",
      "|  7|      Etta|     Hurn|Female|Great Britain| 56|\n",
      "|  8|   Earlean|   Melgar|Female|United States| 27|\n",
      "|  9|  Vincenza|  Weiland|Female|United States| 40|\n",
      "+---+----------+---------+------+-------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## any=How\n",
    "#If 'any', drop a row if it contains any nulls.\n",
    "#     If 'all', drop a row only if all its values are null.\n",
    "df_spark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3490e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+----+\n",
      "|  0|First Name|Last Name|Gender|      Country| Age|\n",
      "+---+----------+---------+------+-------------+----+\n",
      "|  1|     Dulce|    Abril|Female|United States|  32|\n",
      "|  2|      Mara|Hashimoto|Female|Great Britain|  25|\n",
      "|  3|    Philip|     Gent|  Male|       France|  36|\n",
      "|  4|  Kathleen|   Hanner|Female|United States|  25|\n",
      "|  5|   Nereida|  Magwood|Female|United States|  58|\n",
      "|  6|    Gaston|    Brumm|  Male|United States|  24|\n",
      "|  7|      Etta|     Hurn|Female|Great Britain|  56|\n",
      "|  8|   Earlean|   Melgar|Female|United States|  27|\n",
      "|  9|  Vincenza|  Weiland|Female|United States|  40|\n",
      "| 10|      null| Vachhani|  null|        India|  23|\n",
      "| 11|     Vivek|     null|  Male|        India|null|\n",
      "+---+----------+---------+------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Threshold =4\n",
    "# It Will check atleast 4 non-Null Values in a row\n",
    "df_spark.na.drop(how='any',thresh=4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42a50929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+----+\n",
      "|  0|First Name|Last Name|Gender|      Country| Age|\n",
      "+---+----------+---------+------+-------------+----+\n",
      "|  1|     Dulce|    Abril|Female|United States|  32|\n",
      "|  2|      Mara|Hashimoto|Female|Great Britain|  25|\n",
      "|  3|    Philip|     Gent|  Male|       France|  36|\n",
      "|  4|  Kathleen|   Hanner|Female|United States|  25|\n",
      "|  5|   Nereida|  Magwood|Female|United States|  58|\n",
      "|  6|    Gaston|    Brumm|  Male|United States|  24|\n",
      "|  7|      Etta|     Hurn|Female|Great Britain|  56|\n",
      "|  8|   Earlean|   Melgar|Female|United States|  27|\n",
      "|  9|  Vincenza|  Weiland|Female|United States|  40|\n",
      "| 11|     Vivek|     null|  Male|        India|null|\n",
      "+---+----------+---------+------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Subset = Gender\n",
    "# Will delete all the row where Null value is present in Gender column\n",
    "df_spark.na.drop(how='any',subset=['Gender']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04f96107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+--------------+--------------+--------------+----+\n",
      "|  0|    First Name|     Last Name|        Gender|       Country| Age|\n",
      "+---+--------------+--------------+--------------+--------------+----+\n",
      "|  1|         Dulce|         Abril|        Female| United States|  32|\n",
      "|  2|          Mara|     Hashimoto|        Female| Great Britain|  25|\n",
      "|  3|        Philip|          Gent|          Male|        France|  36|\n",
      "|  4|      Kathleen|        Hanner|        Female| United States|  25|\n",
      "|  5|       Nereida|       Magwood|        Female| United States|  58|\n",
      "|  6|        Gaston|         Brumm|          Male| United States|  24|\n",
      "|  7|          Etta|          Hurn|        Female| Great Britain|  56|\n",
      "|  8|       Earlean|        Melgar|        Female| United States|  27|\n",
      "|  9|      Vincenza|       Weiland|        Female| United States|  40|\n",
      "| 10|Missing Values|      Vachhani|Missing Values|         India|  23|\n",
      "| 11|         Vivek|Missing Values|          Male|         India|null|\n",
      "| 12|Missing Values|         Patel|Missing Values|Missing Values|  26|\n",
      "+---+--------------+--------------+--------------+--------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Filling the Missing the Values\n",
    "df_spark.na.fill('Missing Values').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1286849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------+-------------+----+\n",
      "|  0|First Name|Last Name|        Gender|      Country| Age|\n",
      "+---+----------+---------+--------------+-------------+----+\n",
      "|  1|     Dulce|    Abril|        Female|United States|  32|\n",
      "|  2|      Mara|Hashimoto|        Female|Great Britain|  25|\n",
      "|  3|    Philip|     Gent|          Male|       France|  36|\n",
      "|  4|  Kathleen|   Hanner|        Female|United States|  25|\n",
      "|  5|   Nereida|  Magwood|        Female|United States|  58|\n",
      "|  6|    Gaston|    Brumm|          Male|United States|  24|\n",
      "|  7|      Etta|     Hurn|        Female|Great Britain|  56|\n",
      "|  8|   Earlean|   Melgar|        Female|United States|  27|\n",
      "|  9|  Vincenza|  Weiland|        Female|United States|  40|\n",
      "| 10|      null| Vachhani|Missing Values|        India|  23|\n",
      "| 11|     Vivek|     null|          Male|        India|null|\n",
      "| 12|      null|    Patel|Missing Values|         null|  26|\n",
      "+---+----------+---------+--------------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can give list of columns\n",
    "df_spark.na.fill('Missing Values','Gender').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f95d7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+----+\n",
      "|  0|First Name|Last Name|Gender|      Country| Age|\n",
      "+---+----------+---------+------+-------------+----+\n",
      "|  1|     Dulce|    Abril|Female|United States|  32|\n",
      "|  2|      Mara|Hashimoto|Female|Great Britain|  25|\n",
      "|  3|    Philip|     Gent|  Male|       France|  36|\n",
      "|  4|  Kathleen|   Hanner|Female|United States|  25|\n",
      "|  5|   Nereida|  Magwood|Female|United States|  58|\n",
      "|  6|    Gaston|    Brumm|  Male|United States|  24|\n",
      "|  7|      Etta|     Hurn|Female|Great Britain|  56|\n",
      "|  8|   Earlean|   Melgar|Female|United States|  27|\n",
      "|  9|  Vincenza|  Weiland|Female|United States|  40|\n",
      "| 10|      null| Vachhani|  null|        India|  23|\n",
      "| 11|     Vivek|     null|  Male|        India|null|\n",
      "| 12|      null|    Patel|  null|         null|  26|\n",
      "+---+----------+---------+------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "484a9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling INTEGER value\n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age'],\n",
    "    outputCols=['{}_imputed'.format(c) for c in ['Age']]\n",
    ").setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58d7f994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-------------+----+-----------+\n",
      "|  0|First Name|Last Name|Gender|      Country| Age|Age_imputed|\n",
      "+---+----------+---------+------+-------------+----+-----------+\n",
      "|  1|     Dulce|    Abril|Female|United States|  32|         32|\n",
      "|  2|      Mara|Hashimoto|Female|Great Britain|  25|         25|\n",
      "|  3|    Philip|     Gent|  Male|       France|  36|         36|\n",
      "|  4|  Kathleen|   Hanner|Female|United States|  25|         25|\n",
      "|  5|   Nereida|  Magwood|Female|United States|  58|         58|\n",
      "|  6|    Gaston|    Brumm|  Male|United States|  24|         24|\n",
      "|  7|      Etta|     Hurn|Female|Great Britain|  56|         56|\n",
      "|  8|   Earlean|   Melgar|Female|United States|  27|         27|\n",
      "|  9|  Vincenza|  Weiland|Female|United States|  40|         40|\n",
      "| 10|      null| Vachhani|  null|        India|  23|         23|\n",
      "| 11|     Vivek|     null|  Male|        India|null|         33|\n",
      "| 12|      null|    Patel|  null|         null|  26|         26|\n",
      "+---+----------+---------+------+-------------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add Imputer cols to df_spark\n",
    "imputer.fit(df_spark).transform(df_spark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b37d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8d2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
